{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e927bb02",
   "metadata": {},
   "source": [
    "# AI Fairness in Medicine: Integrated and Interactive Workshop\n",
    "\n",
    "Let\"s take off our hats as medical staff and wear a new hat, AI developer, for a few hours. In the\n",
    "end of this session, you will understand the basics of developing an AI solution for medical usage\n",
    "through a simple example. You will also understand what is biases in AI development, their effects,\n",
    "and a general idea on how to develop a fair AI solution.\n",
    "\n",
    "There is no need to freak out even though you have zero experience in programming or even AI! This\n",
    "material (which data scientists usually call it *notebook*) provides you a quick tutorial on the\n",
    "machine learning lifecycle and does all the programming parts for you already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fd19e",
   "metadata": {},
   "source": [
    "## Part I: What does it mean to train an AI model?\n",
    "\n",
    "There is no perfect answer in solving a problem using AI. There are many frameworks and methodology\n",
    "that differ by the details, but the starting point is to understand what is the problem, what are\n",
    "the data we have, and what is the goal to achieve using AI.\n",
    "\n",
    "For example, in the context of medicine, an example problem could be to diagnose the patients given\n",
    "a set of symptoms, to screen diseases or disorders given patient\"s imaging data, or to discover\n",
    "new vaccine when the next pandemic arrives.\n",
    "\n",
    "The diagram below depicts one viewpoint of the machine learning lifecycle. It explains briefly the\n",
    "process of building an AI model to solve the predefined problem and to achieve the predefined goal.\n",
    "\n",
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg\"\n",
    "alt=\"ml-lifecycle\" width=\"400\"/>\n",
    "\n",
    "*Source: https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg*\n",
    "\n",
    "1. **Data Collection**\n",
    "\n",
    "   We start by gathering relevant medical information like patient records, lab results, and imaging\n",
    "   scans. AI developers must understand the problem well, especially in the medical context, and\n",
    "   should find relevant data, or the resources, to build the AI solution efficiently.\n",
    "\n",
    "2. **Data Cleaning**\n",
    "\n",
    "   The raw data often contains errors, missing values, or inconsistencies that need fixing. We\n",
    "   carefully review and correct these issues to ensure the information is accurate and reliable for\n",
    "   analysis.\n",
    "\n",
    "3. **Feature Engineering**\n",
    "\n",
    "   This is when *inductive bias* first comes in. Here we identify and organize the most important\n",
    "   pieces of medical data that do not exist originally in the data, but we complement them to help\n",
    "   AI become more accurate. For example, we might calculate BMI from height and weight measurements,\n",
    "   or track changes in lab values over time instead of given AI the raw values.\n",
    "\n",
    "4. **Model Training**\n",
    "\n",
    "    The AI model learns to capture patterns from between the collected data and the task\"s goal\n",
    "    after AI developers provide a set of constraints or rules. For example, capturing the hidden\n",
    "    relationship between a protein and the docking site or recognizing the pattern between apneic\n",
    "    episode and the SpO2 signal. This AI model can also be large language models (LLM) that we hear\n",
    "    everyday in some specific tasks!\n",
    "\n",
    "5. **Evaluation**\n",
    "\n",
    "    After the model has learned from the data, we rigorously test its performance using metrics\n",
    "    doctors understand, like sensitivity and specificity. We also check for biases to ensure that\n",
    "    the patterns the model learned are fair and accurate across different patient groups before\n",
    "    clinical use.\n",
    "\n",
    "6. **Deployment**\n",
    "\n",
    "    Once validated, we integrate the model into hospital systems where it can assist with tasks like\n",
    "    flagging abnormal test results. This is done carefully with proper staff training and monitoring\n",
    "    protocols.\n",
    "\n",
    "7. **Monitoring**\n",
    "\n",
    "    After launch, we continuously track the model\"s performance in real-world use. Just like medical\n",
    "    guidelines evolve, we update the models as we get new data or discover ways to improve them.\n",
    "\n",
    "This ongoing cycle helps create AI tools that truly support clinical work while maintaining safety\n",
    "and reliability. Your expertise remains essential for interpreting results and making final\n",
    "decisions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024d295",
   "metadata": {},
   "source": [
    "## Part II: Let\"s build your first medical AI model!\n",
    "\n",
    "In this workshop, we will use a real-world medical dataset from the\n",
    "[WiDS Datathon 2020](https://www.kaggle.com/competitions/widsdatathon2020/data), which contains\n",
    "anonymized patient records from intensive care units (ICUs) around the world. The dataset includes a\n",
    "wide range of clinical features such as demographics, vital signs, laboratory results, and\n",
    "comorbidities collected during the first 24 hours of a patient\"s ICU stay.\n",
    "\n",
    "While the original competition focused on predicting in-hospital mortality (`hospital_death`), our\n",
    "goal will be to develop a model that predicts whether a patient has cirrhosis, using the `cirrhosis`\n",
    "column as our target variable. This shift allows us to explore the challenges and considerations\n",
    "involved in building AI models for different clinical outcomes, while practicing essential steps in\n",
    "the machine learning workflow.\n",
    "\n",
    "Let\"s first load the data and visualize it to understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4adb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "sns.set_theme(style=\"white\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c33f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/training_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eef314",
   "metadata": {},
   "source": [
    "This is how our data looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b451fe",
   "metadata": {},
   "source": [
    "Plot below shows the distribution of each demographic traits including age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.histplot(data=df, x=\"age\", ax=axes[0])\n",
    "sns.histplot(data=df, x=\"gender\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd3568",
   "metadata": {},
   "source": [
    "This dataset also contains the prevalence of 6 diseases: leukemia, hepatic failure,\n",
    "immunosuppression, lymphoma, cirrhosis, and aids. Let's take a quick look on how each disease\n",
    "prevalence distributes across gender and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db710c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASES = [\"leukemia\", \"hepatic_failure\", \"immunosuppression\", \"lymphoma\", \"cirrhosis\", \"aids\"]\n",
    "long_df = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"patient_id\", \"gender\", \"ethnicity\"],\n",
    "    value_vars=DISEASES,\n",
    "    value_name=\"presence\",\n",
    "    var_name=\"disease\",\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=long_df[long_df[\"presence\"] == 1],\n",
    "    x=\"disease\",\n",
    "    col=\"gender\",\n",
    "    hue=\"disease\",\n",
    "    kind=\"count\",\n",
    "    aspect=2,\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2851bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", font_scale=1.5)\n",
    "g = sns.catplot(\n",
    "    data=long_df[long_df[\"presence\"] == 1],\n",
    "    x=\"disease\",\n",
    "    col=\"ethnicity\",\n",
    "    col_wrap=3,\n",
    "    hue=\"disease\",\n",
    "    kind=\"count\",\n",
    "    legend=False,\n",
    "    aspect=1.5,\n",
    ")\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis=\"x\", rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b05c44",
   "metadata": {},
   "source": [
    "**üîç Findings**\n",
    "\n",
    "- **Mean age is 62**, left skewed. Younger people are underrepresented.\n",
    "- **Similar number of males and females but men are likely to have disease**.\n",
    "  \n",
    "  The difference is significant in cirrhosis, hepatic failure, aids, and leukemia. An educated guess\n",
    "  for the greater prevalence of cirrhosis and aids in men could be that they drink more and are prone\n",
    "  to higher risk in sexual behaviors respectively.\n",
    "- **77% of patients are white**.\n",
    "  \n",
    "  Although white patients are the majority, they show a unique distribution of the disease prevalence\n",
    "  compared to other ethnicities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545c7a1",
   "metadata": {},
   "source": [
    "There are also other data attributes that we can extract from the data. These attributes are what\n",
    "we usually call them *features* in the context of machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103597c",
   "metadata": {},
   "source": [
    "Let's take a look at a few examples of the features we have. As our problem is to predict whether a\n",
    "particular has cirrhosis, we handpicked a few features that are likely related to liver function\n",
    "(such as albumin, bilirubin, INR, platelets, and age). In the following cells, we visualize the\n",
    "distributions of these features for patients with and without cirrhosis.\n",
    "\n",
    "This process is part of Exploratory Data Analysis (EDA), a crucial step for machine learning\n",
    "practitioners. EDA helps us understand the data, identify patterns, spot anomalies, and select\n",
    "relevant features, ultimately guiding better model development and reducing the risk of bias or\n",
    "errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94385dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_FEATURES = [\n",
    "    \"d1_albumin_max\",\n",
    "    \"d1_albumin_min\",\n",
    "    \"d1_bilirubin_max\",\n",
    "    \"d1_bilirubin_min\",\n",
    "    \"d1_inr_max\",\n",
    "    \"d1_inr_min\",\n",
    "    \"d1_platelets_max\",\n",
    "    \"d1_platelets_min\",\n",
    "    \"age\",    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50879e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"patient_id\", \"cirrhosis\"],\n",
    "    value_vars=DISPLAY_FEATURES,\n",
    "    value_name=\"value\",\n",
    "    var_name=\"feature\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=long_df,\n",
    "    x=\"value\",\n",
    "    hue=\"cirrhosis\",\n",
    "    col=\"feature\",\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    "    common_bins=False,\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    "    aspect=3,\n",
    "    col_wrap=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f998c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with this\n",
    "FEATURES = [\n",
    "    \"d1_albumin_max\", \"d1_albumin_min\",\n",
    "    \"d1_inr_max\",\"d1_inr_min\",\n",
    "    \"d1_bilirubin_max\", \"d1_bilirubin_min\",\n",
    "    \"d1_platelets_min\",\n",
    "    \"map_apache\", \"d1_mbp_min\",\n",
    "    \"creatinine_apache\", \"d1_creatinine_max\",\n",
    "    \"urineoutput_apache\", \n",
    "    \"bun_apache\",\n",
    "    \"d1_sodium_min\", \"d1_potassium_max\",\n",
    "    \"d1_temp_max\", \"d1_temp_min\",\n",
    "    \"d1_wbc_max\", \"d1_wbc_min\",\n",
    "    \"d1_lactate_max\"\n",
    "]\n",
    "GROUPS = [\"patient_id\", \"gender\", \"age\", \"ethnicity\"]\n",
    "TARGET = \"cirrhosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df, features: list[str], target: str, groups: list[str],\n",
    "                       use_ethnicity: bool, everyone_as_african_american: bool = False):\n",
    "    # Preprocess target column. We don't subjects with undefined value on the \"cirrhosis\" column.\n",
    "    df = df.dropna(subset=[TARGET])\n",
    "\n",
    "    if use_ethnicity:\n",
    "        features = features[:] + [\"ethnicity\"]\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    group = df[groups]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test, _, group_test = train_test_split(\n",
    "        X, y, group, test_size=0.3, random_state=42)\n",
    "\n",
    "    if everyone_as_african_american and use_ethnicity:\n",
    "        X_test[\"ethnicity\"] = \"African American\"\n",
    "\n",
    "    float_transformer = Pipeline([\n",
    "        # Preprocess/clean the data with N/A values.\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Convert ethnicity if available, add it at the front of the pipeline\n",
    "    if use_ethnicity:\n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"encoder\", OrdinalEncoder(), [\"ethnicity\"]),\n",
    "            ],\n",
    "            remainder=float_transformer,\n",
    "        )\n",
    "    else:\n",
    "        transformer = float_transformer\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"transformer\", transformer),\n",
    "        # Add our classifier.\n",
    "        (\"classifier\", RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            min_samples_split=10,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Fit the model to the training data and make predictions on the test data\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"ground_truth\": y_test,\n",
    "        \"prediction\": y_pred,\n",
    "    })\n",
    "    result_df[\"TP\"] = (result_df[\"ground_truth\"] == 1) & (result_df[\"prediction\"] == 1)\n",
    "    result_df[\"TN\"] = (result_df[\"ground_truth\"] == 0) & (result_df[\"prediction\"] == 0)\n",
    "    result_df[\"FP\"] = (result_df[\"ground_truth\"] == 0) & (result_df[\"prediction\"] == 1)\n",
    "    result_df[\"FN\"] = (result_df[\"ground_truth\"] == 1) & (result_df[\"prediction\"] == 0)\n",
    "\n",
    "    result_df = pd.concat([result_df, group_test], axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a90f47",
   "metadata": {},
   "source": [
    "Now let's practice what we have discussed. From the list below, choose **two** or **three** problems\n",
    "that you are familiar with then proceed.\n",
    "\n",
    "Given a problem and a goal, which types of patient data should we collect? And how would it help\n",
    "constructing an accurate model? What are the other use cases in ICU care or medical practice that we\n",
    "can apply this solution to? Do they have the same format of data? Can we apply the same data\n",
    "cleaning method? If you cannot think of any, what about applying the same modeling technique to the\n",
    "following problems?\n",
    "\n",
    "1. Estimating ST-elevation from ECG signal\n",
    "2. Detecting lung cancer from CXR images\n",
    "3. Adjusting insulin dose from CGM data\n",
    "4. Sepsis prediction in the ICU\n",
    "5. Early warning system (EWS) for deterioration\n",
    "6. Data extraction from clinician notes for flowsheets\n",
    "7. Bed management\n",
    "\n",
    "Discuss your thoughts with your group!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a313770",
   "metadata": {},
   "source": [
    "## Part III: Monitoring your AI model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ad63b",
   "metadata": {},
   "source": [
    "A confusion matrix is a fundamental tool for evaluating the performance of a classification model.\n",
    "It is a table that summarizes the number of correct and incorrect predictions made by the model,\n",
    "broken down by each class. The matrix displays counts of true positives (TP), true negatives (TN),\n",
    "false positives (FP), and false negatives (FN), allowing us to see not only the overall accuracy but\n",
    "also the types of errors the model is making. This detailed breakdown helps identify whether the\n",
    "model is biased toward certain classes or is systematically making specific types of mistakes.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/377027146/figure/fig5/AS:11431281215285308@1704113587226/The-Matrix-of-TP-FP-FN-TN-Precision-Recall-dan-Accuracy.ppm\"\n",
    "alt=\"cm-definition\" width=\"400\"/>\n",
    "\n",
    "Beyond the confusion matrix, other important evaluation metrics include precision, recall\n",
    "(sensitivity), specificity, F1-score, and the area under the receiver operating characteristic curve\n",
    "(AUC-ROC).\n",
    "\n",
    "- **Precision** measures the proportion of positive predictions that are actually correct.\n",
    "- **Recall** measures the proportion of actual positives that are correctly identified.\n",
    "- The **F1-score** provides a balance between precision and recall, especially useful in imbalanced\n",
    "  datasets.\n",
    "- **AUC-ROC** evaluates the models ability to distinguish between classes across different thresholds.\n",
    "\n",
    "These metrics provide a more comprehensive understanding of model performance, especially in medical\n",
    "or high-stakes applications where certain types of errors may have greater consequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c76021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_df(data: pd.DataFrame):\n",
    "    _, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    kwargs = {\"annot\": True, \"robust\": True, \"fmt\": \"d\"}\n",
    "    _ = sns.heatmap(data=data.groupby(\"ethnicity\")[[\"TP\", \"TN\", \"FP\", \"FN\"]].sum(), ax=axes[0], **kwargs)\n",
    "    _ = sns.heatmap(data=data.groupby(\"gender\")[[\"TP\", \"TN\", \"FP\", \"FN\"]].sum(), ax=axes[1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73239b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df, features=FEATURES, target=TARGET, groups=GROUPS, use_ethnicity=True)\n",
    "plot_result_df(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa9644",
   "metadata": {},
   "source": [
    "The model simply says __\"no cirrhosis\"__ to almost everybody! Especially for the African American\n",
    "and Asian groups, the model never says \"cirrhosis\".\n",
    "\n",
    "What did we do wrong? We will see in the next section how we can improve this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253594a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Before continuing, based on the problems you selected earlier, what should be the evaluation metrics\n",
    "for those problems?\n",
    "\n",
    "1. Sepsis prediction in the ICU\n",
    "2. Early warning system (EWS)\n",
    "3. Data extraction from clinician notes for flowsheets\n",
    "4. Bed management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a86920",
   "metadata": {},
   "source": [
    "## Part IV: Removing the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d97bda",
   "metadata": {},
   "source": [
    "Previously, we utilized the ethnicity as one of the features. To test if the model is towards a\n",
    "specific ethnic group, we can intentionally set the \"ethnicity\" of everyone to, say, \"African\n",
    "American\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937cf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df, features=FEATURES, target=TARGET, groups=GROUPS,\n",
    "                               use_ethnicity=True, everyone_as_african_american=True)\n",
    "plot_result_df(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c28fb",
   "metadata": {},
   "source": [
    "Interestingly, when masking out the ethnic group by telling the model every subject is African\n",
    "American, the model never predicts \"cirrhosis\" to Hispanic and unknown groups. This implies that by\n",
    "using ethnicity as one of the features, the model is capturing that information as a part of its\n",
    "decision engine.\n",
    "\n",
    "We can fix this problem by excluding the \"ethnicity\" feature from the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfea975",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df, features=FEATURES, target=TARGET, groups=GROUPS, use_ethnicity=False)\n",
    "plot_result_df(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70976afb",
   "metadata": {},
   "source": [
    "The results are slightly better although not promising. Another data bias in this dataset not yet\n",
    "handled properly is the *imbalanced dataset*.\n",
    "\n",
    "Imbalanced datasets pose a significant challenge in medical AI because the model may learn to favor\n",
    "the majority class, leading to poor detection of rare but critical conditions. For example, if only\n",
    "a small fraction of patients have cirrhosis, a model might simply predict \"no cirrhosis\" for\n",
    "everyone and still achieve high accuracy, but fail to identify actual cases.\n",
    "\n",
    "To address this, we can:\n",
    "- Use evaluation metrics like precision, recall, and F1-score instead of accuracy.\n",
    "- Apply resampling techniques such as oversampling the minority class or undersampling the majority\n",
    "  class.\n",
    "- Employ algorithms or loss functions designed to handle imbalance.\n",
    "- Collect more data for underrepresented groups if possible.\n",
    "\n",
    "These strategies help ensure the model learns to recognize both common and rare outcomes, improving\n",
    "fairness and clinical utility!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43540b",
   "metadata": {},
   "source": [
    "At the end of this material, let's take a step further and discuss with the team of this issue.\n",
    "\n",
    "- Can you think of any example that bias would help training a more accurate model? And why would\n",
    "  the bias help?\n",
    "- Stick to that example. How do you know it is a fair bias? Or alternatively, how do you know if it\n",
    "  is unfair?\n",
    "- How can we prevent bias into machine learning lifecycle?\n",
    "- How do we know if ChatGPT is safe from bias? What questions should we ask in order to know the\n",
    "  answer?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-icu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
