{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4adb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run workshop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927bb02",
   "metadata": {},
   "source": [
    "# AI Fairness in Medicine: Integrated and Interactive Workshop\n",
    "\n",
    "Let's take off our hats as medical staff and wear a new hat, AI developer, for a few hours. In the\n",
    "end of this session, you will understand the basics of developing an AI solution for medical usage\n",
    "through a simple example. You will also understand what is biases in AI development, their effects,\n",
    "and a general idea on how to develop a fair AI solution.\n",
    "\n",
    "There is no need to freak out even though you have zero experience in programming or even AI! This\n",
    "material (which data scientists usually call it *notebook*) provides you a quick tutorial on the\n",
    "machine learning lifecycle and does all the programming parts for you already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fd19e",
   "metadata": {},
   "source": [
    "## Part I: What does it mean to train an AI model?\n",
    "\n",
    "There is no perfect answer in solving a problem using AI. There are many frameworks and methodology\n",
    "that differ by the details, but the starting point is to understand what is the problem, what are\n",
    "the data we have, and what is the goal to achieve using AI.\n",
    "\n",
    "For example, in the context of medicine, an example problem could be to diagnose the patients given\n",
    "a set of symptoms, to screen diseases or disorders given patient's imaging data, or to discover\n",
    "new vaccine when the next pandemic arrives.\n",
    "\n",
    "The diagram below depicts one viewpoint of the machine learning lifecycle. It explains briefly the\n",
    "process of building an AI model to solve the predefined problem and to achieve the predefined goal.\n",
    "\n",
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg\"\n",
    "alt=\"ml-lifecycle\" width=\"400\"/>\n",
    "\n",
    "*Source: https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg*\n",
    "\n",
    "1. **Data Collection**\n",
    "\n",
    "   We start by gathering relevant medical information like patient records, lab results, and imaging\n",
    "   scans. AI developers must understand the problem well, especially in the medical context, and\n",
    "   should find relevant data, or the resources, to build the AI solution efficiently.\n",
    "\n",
    "2. **Data Cleaning**\n",
    "\n",
    "   The raw data often contains errors, missing values, or inconsistencies that need fixing. We\n",
    "   carefully review and correct these issues to ensure the information is accurate and reliable for\n",
    "   analysis.\n",
    "\n",
    "3. **Feature Engineering**\n",
    "\n",
    "   This is when *inductive bias* first comes in. Here we identify and organize the most important\n",
    "   pieces of medical data that do not exist originally in the data, but we complement them to help\n",
    "   AI become more accurate. For example, we might calculate BMI from height and weight measurements,\n",
    "   or track changes in lab values over time instead of given AI the raw values.\n",
    "\n",
    "4. **Model Training**\n",
    "\n",
    "    The AI model learns to capture patterns from between the collected data and the task\"s goal\n",
    "    after AI developers provide a set of constraints or rules. For example, capturing the hidden\n",
    "    relationship between a protein and the docking site or recognizing the pattern between apneic\n",
    "    episode and the SpO2 signal. This AI model can also be large language models (LLM) that we hear\n",
    "    everyday in some specific tasks!\n",
    "\n",
    "5. **Evaluation**\n",
    "\n",
    "    After the model has learned from the data, we rigorously test its performance using metrics\n",
    "    doctors understand, like sensitivity and specificity. We also check for biases to ensure that\n",
    "    the patterns the model learned are fair and accurate across different patient groups before\n",
    "    clinical use.\n",
    "\n",
    "6. **Deployment**\n",
    "\n",
    "    Once validated, we integrate the model into hospital systems where it can assist with tasks like\n",
    "    flagging abnormal test results. This is done carefully with proper staff training and monitoring\n",
    "    protocols.\n",
    "\n",
    "7. **Monitoring**\n",
    "\n",
    "    After launch, we continuously track the model\"s performance in real-world use. Just like medical\n",
    "    guidelines evolve, we update the models as we get new data or discover ways to improve them.\n",
    "\n",
    "This ongoing cycle helps create AI tools that truly support clinical work while maintaining safety\n",
    "and reliability. Your expertise remains essential for interpreting results and making final\n",
    "decisions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024d295",
   "metadata": {},
   "source": [
    "## Part II: Let's build your first medical AI model!\n",
    "\n",
    "In this workshop, we will use a real-world medical dataset from the\n",
    "[WiDS Datathon 2020](https://www.kaggle.com/competitions/widsdatathon2020/data), which contains\n",
    "anonymized patient records from intensive care units (ICUs) around the world. The dataset includes a\n",
    "wide range of clinical features such as demographics, vital signs, laboratory results, and\n",
    "comorbidities collected during the first 24 hours of a patient's ICU stay.\n",
    "\n",
    "While the original competition focused on predicting in-hospital mortality (`hospital_death`), our\n",
    "goal will be to develop a model that predicts whether a patient has cirrhosis, using the `cirrhosis`\n",
    "column as our target variable. This shift allows us to explore the challenges and considerations\n",
    "involved in building AI models for different clinical outcomes, while practicing essential steps in\n",
    "the machine learning workflow.\n",
    "\n",
    "Before delving into the data, here is the dataset description for WiDS Datathon 2020.\n",
    "\n",
    "> The challenge is to create a model that uses data from the first 24 hours of intensive care to\n",
    "> predict patient survival. MIT's GOSSIS community initiative, with privacy certification from the\n",
    "> Harvard Privacy Lab, has provided a dataset of more than 130,000 hospital Intensive Care Unit\n",
    "> (ICU) visits from patients, spanning a one-year timeframe. This data is part of a growing global\n",
    "> effort and consortium spanning Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than\n",
    "> 200 hospitals in the United States.\n",
    "\n",
    "Do you notice any bias during the data collection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eef314",
   "metadata": {},
   "source": [
    "Let's first load the data and visualize it to understand it better. Below is a sample of our data.\n",
    "We only see a few rows and a few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe(\"./data/training_v2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b451fe",
   "metadata": {},
   "source": [
    "Plot below shows the distribution of each demographic traits including age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "sns.histplot(data=df, x=\"age\", ax=axes[0], discrete=True)\n",
    "sns.histplot(data=df, x=\"gender\", ax=axes[1])\n",
    "\n",
    "ethnicity_counts = df[\"ethnicity\"].value_counts()\n",
    "axes[2].pie(\n",
    "    ethnicity_counts.values,\n",
    "    labels=ethnicity_counts.index,\n",
    ")\n",
    "axes[2].axis(\"equal\")\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd3568",
   "metadata": {},
   "source": [
    "This dataset also contains the prevalence of 6 diseases: leukemia, hepatic failure,\n",
    "immunosuppression, lymphoma, cirrhosis, and aids. Let's take a quick look on how each disease\n",
    "prevalence distributes across gender and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c38224-2b76-4141-8db6-6a99db98bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_of_diseases(df, group_by=\"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f9a3a-d0af-4db2-b5cc-79a05e88d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_of_diseases(df, group_by=\"ethnicity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b05c44",
   "metadata": {},
   "source": [
    "**üîç Findings**\n",
    "\n",
    "- **Mean age is 62**, left skewed. Younger people are underrepresented.\n",
    "- **Men is underrepresented. Diseases are more common in men**.\n",
    "  The difference is significant in cirrhosis, hepatic failure, aids, and leukemia. Let's discuss why might be the reasons.\n",
    "- **77% of patients are white**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545c7a1",
   "metadata": {},
   "source": [
    "There are also other data attributes that we can extract from the data. These attributes are what\n",
    "we usually call them *features* in the context of machine learning. \n",
    "\n",
    "The followings are some of the data we had gathered. For each of the name, we record the maximum and minimum values during the first hour and the first day of the visit. In addition, we have demographic details such that age, gender, ethnicity, weight, height, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562e6d2-de79-4a4c-a16d-fe44b0b938cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_feature_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90486c9-aa3b-4174-8c94-27bb37af27c1",
   "metadata": {},
   "source": [
    "We use the convention that prefixes `d1` and `h1` represent the record of the first day and the first hour respectively, and the suffixes `max` and `min` represent the maximal and the minimal value recorded during that period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103597c",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c8e6-ce8d-4a94-b300-405b31a67e4e",
   "metadata": {},
   "source": [
    "For now, let's focus on only one bias we found in the dataset, that is, cirrhosis is more common in men than in women. The following plot shows that the ratio of male patient is around 3 times that of female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261d52e-05f6-4fc1-83f0-5d320da64994",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_of_cirrhosis(df, group_by=\"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c17af-34b2-44ff-8139-db840bc35414",
   "metadata": {},
   "source": [
    "We selected these features for a basic model, but feel free to add or remove ones you think are irrelevant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f998c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_FEATURES = [\n",
    "    \"d1_albumin_max\", \"d1_albumin_min\",\n",
    "    \"d1_inr_max\",\"d1_inr_min\",\n",
    "    \"d1_bilirubin_max\", \"d1_bilirubin_min\",\n",
    "    \"d1_platelets_min\", \n",
    "    \"d1_mbp_min\",\n",
    "    \"d1_creatinine_max\",\n",
    "    \"d1_sodium_min\", \n",
    "    \"d1_potassium_max\",\n",
    "    \"d1_temp_max\", \"d1_temp_min\",\n",
    "    \"d1_wbc_max\", \"d1_wbc_min\",\n",
    "    \"d1_lactate_max\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bcb5b-4a5d-4ac0-9241-21afd95e06f9",
   "metadata": {},
   "source": [
    "To keep things simple, we have written a function to train and evaluate the model given the dataset and features to be used. The model is a random forest classifier. If you want to see the full implementation, headover to the python `workshop.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a90f47",
   "metadata": {},
   "source": [
    "Now let's practice what we have discussed. From the list below, choose **two** or **three** problems\n",
    "that you are familiar with then proceed.\n",
    "\n",
    "Given a problem and a goal, which types of patient data should we collect? And how would it help\n",
    "constructing an accurate model? What are the other use cases in ICU care or medical practice that we\n",
    "can apply this solution to? Do they have the same format of data? Can we apply the same data\n",
    "cleaning method? If you cannot think of any, what about applying the same modeling technique to the\n",
    "following problems?\n",
    "\n",
    "1. Estimating ST-elevation from ECG signal\n",
    "2. Detecting lung cancer from CXR images\n",
    "3. Adjusting insulin dose from CGM data\n",
    "4. Sepsis prediction in the ICU\n",
    "5. Early warning system (EWS) for deterioration\n",
    "6. Data extraction from clinician notes for flowsheets\n",
    "7. Bed management\n",
    "\n",
    "Discuss your thoughts with your group!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a313770",
   "metadata": {},
   "source": [
    "## Part III: Monitoring your AI model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ad63b",
   "metadata": {},
   "source": [
    "A confusion matrix is a fundamental tool for evaluating the performance of a classification model.\n",
    "It is a table that summarizes the number of correct and incorrect predictions made by the model,\n",
    "broken down by each class. The matrix displays counts of true positives (TP), true negatives (TN),\n",
    "false positives (FP), and false negatives (FN), allowing us to see not only the overall accuracy but\n",
    "also the types of errors the model is making. This detailed breakdown helps identify whether the\n",
    "model is biased toward certain classes or is systematically making specific types of mistakes.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/377027146/figure/fig5/AS:11431281215285308@1704113587226/The-Matrix-of-TP-FP-FN-TN-Precision-Recall-dan-Accuracy.ppm\"\n",
    "alt=\"cm-definition\" width=\"400\"/>\n",
    "\n",
    "Beyond the confusion matrix, other important evaluation metrics include precision, recall\n",
    "(sensitivity), specificity, F1-score, and the area under the receiver operating characteristic curve\n",
    "(AUC-ROC).\n",
    "\n",
    "- **Precision** measures the proportion of positive predictions that are actually correct.\n",
    "- **Recall** measures the proportion of actual positives that are correctly identified.\n",
    "- The **F1-score** provides a balance between precision and recall, especially useful in imbalanced\n",
    "  datasets.\n",
    "- **AUC-ROC** evaluates the models ability to distinguish between classes across different thresholds.\n",
    "\n",
    "These metrics provide a more comprehensive understanding of model performance, especially in medical\n",
    "or high-stakes applications where certain types of errors may have greater consequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253594a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Before continuing, based on the problems you selected earlier, what should be the evaluation metrics for those problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193451e6-36c3-496d-8b37-eaae4b3224dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df,\n",
    "                               numerical_features=BASIC_FEATURES,\n",
    "                               categorical_features=[\"gender\"],\n",
    "                               target=\"cirrhosis\",\n",
    "                              )\n",
    "plot_model_result(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b0ada-996b-4055-a558-79e429019436",
   "metadata": {},
   "source": [
    "The accuracy and the Recall is quite high. Is that what we want? Is that all we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050623b2-2949-4658-aa22-f38669796cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df,\n",
    "                               numerical_features=BASIC_FEATURES,\n",
    "                               categorical_features=[\"gender\"],\n",
    "                               target=\"cirrhosis\",\n",
    "                               everyone_as_male=True\n",
    "                               )\n",
    "plot_model_result(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f305f-6e1f-449f-ac14-b45f78d5fc81",
   "metadata": {},
   "source": [
    "Nope, if we mistakenly say that a female patient is male, then the prediction changes drastically although there is no biological reason to expect so. \n",
    "\n",
    "You can see the difference between the last two figures. The first one is a normal one and the second one is the one where we say everyone are male. We have a lot more True Positive female patients!\n",
    "\n",
    "Now, before we look into how we can mitigate the gender bias, could you see how does this bias occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93754118-70d7-4b8e-91bc-56b949e49ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df,\n",
    "                               numerical_features=BASIC_FEATURES,\n",
    "                               categorical_features=[\"gender\"],\n",
    "                               target=\"cirrhosis\",\n",
    "                               mitigate_bias=mitigate_gender_bias,\n",
    "                               )\n",
    "plot_model_result(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a6c6f-53be-44df-8b32-6d4d952a6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_and_evaluate(df=df,\n",
    "                               numerical_features=BASIC_FEATURES,\n",
    "                               categorical_features=[\"gender\"],\n",
    "                               target=\"cirrhosis\",\n",
    "                               mitigate_bias=mitigate_gender_bias,\n",
    "                               everyone_as_male=True\n",
    "                               )\n",
    "plot_model_result(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15f282-b518-44ce-a5fa-64a8a6c5060d",
   "metadata": {},
   "source": [
    "Now, misrepresenting the gender does not affect much!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21342637-ea07-47d1-888b-63a11c8c44c8",
   "metadata": {},
   "source": [
    "Imbalaced datasets pose a significant challenge in medical AI because the model may learn to favor the majority class, leading to poor detection of rate but critical conditions. In this case, the ratio of male patients is three time that of female. This means that the model try to favor the majority by saying that men have cirrhosis and women don't. \n",
    "\n",
    "We addressed this issue by resampling the dataset as we know for a fact that biologically, men and women has similar risk for cirrhosis, therefore. We resample the dataset so that the new dataset has the same ratio of male and female patient, the model then performed better.\n",
    "\n",
    "At the end, let us take a step further and discuss these issues: \n",
    "- Can you think of any example that bias would help training a more accurate model, or when are biases useful?\n",
    "- Stick to that example, how do you know that the bias is fair or unfair, good or bad.\n",
    "- How can we prevent the bias into machine learning life cycle?\n",
    "- How do we know if ChatGPT is safe from bias? What questions should we ask in order to know the answer?\n",
    "- How should we use ChatGPT, knowing that it has bias?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-icu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
