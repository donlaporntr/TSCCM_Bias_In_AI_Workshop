{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e927bb02",
   "metadata": {},
   "source": [
    "# AI Fairness in Medicine: Integrated and Interactive Workshop\n",
    "\n",
    "Let's take off our hats as medical staff and wear a new hat, AI developer, for a few hours. In the\n",
    "end of this session, you will understand the basics of developing an AI solution for medical usage\n",
    "through a simple example. You will also understand what is biases in AI development, their effects,\n",
    "and a general idea on how to develop a fair AI solution.\n",
    "\n",
    "There is no need to freak out even though you have zero experience in programming or even AI! This\n",
    "material (which data scientists usually call it *notebook*) provides you a quick tutorial on the\n",
    "machine learning lifecycle and does all the programming parts for you already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fd19e",
   "metadata": {},
   "source": [
    "## Part I: What does it mean to train an AI model?\n",
    "\n",
    "There is no perfect answer in solving a problem using AI. There are many frameworks and methodology\n",
    "that differ by the details, but the starting point is to understand what is the problem, what are\n",
    "the data we have, and what is the goal to achieve using AI.\n",
    "\n",
    "For example, in the context of medicine, an example problem could be to diagnose the patients given\n",
    "a set of symptoms, to screen diseases or disorders given patient's imaging data, or to discover\n",
    "new vaccine when the next pandemic arrives.\n",
    "\n",
    "The diagram below depicts one viewpoint of the machine learning lifecycle. It explains briefly the\n",
    "process of building an AI model to solve the predefined problem and to achieve the predefined goal.\n",
    "\n",
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg\"\n",
    "alt=\"ml-lifecycle\" width=\"400\"/>\n",
    "\n",
    "*Source: https://towardsdatascience.com/wp-content/uploads/2024/11/1_dlG-Cju5ke-DKp8DQ9hiA@2x.jpeg*\n",
    "\n",
    "1. **Data Collection**\n",
    "\n",
    "   We start by gathering relevant medical information like patient records, lab results, and imaging\n",
    "   scans. AI developers must understand the problem well, especially in the medical context, and\n",
    "   should find relevant data, or the resources, to build the AI solution efficiently.\n",
    "\n",
    "2. **Data Cleaning**\n",
    "\n",
    "   The raw data often contains errors, missing values, or inconsistencies that need fixing. We\n",
    "   carefully review and correct these issues to ensure the information is accurate and reliable for\n",
    "   analysis.\n",
    "\n",
    "3. **Feature Engineering**\n",
    "\n",
    "   This is when *inductive bias* first comes in. Here we identify and organize the most important\n",
    "   pieces of medical data that do not exist originally in the data, but we complement them to help\n",
    "   AI become more accurate. For example, we might calculate BMI from height and weight measurements,\n",
    "   or track changes in lab values over time instead of given AI the raw values.\n",
    "\n",
    "4. **Model Training**\n",
    "\n",
    "    The AI model learns to capture patterns from between the collected data and the task's goal\n",
    "    after AI developers provide a set of constraints or rules. For example, capturing the hidden\n",
    "    relationship between a protein and the docking site or recognizing the pattern between apneic\n",
    "    episode and the SpO2 signal. This AI model can also be large language models (LLM) that we hear\n",
    "    everyday in some specific tasks!\n",
    "\n",
    "5. **Evaluation**\n",
    "\n",
    "    After the model has learned from the data, we rigorously test its performance using metrics\n",
    "    doctors understand, like sensitivity and specificity. We also check for biases to ensure that\n",
    "    the patterns the model learned are fair and accurate across different patient groups before\n",
    "    clinical use.\n",
    "\n",
    "6. **Deployment**\n",
    "\n",
    "    Once validated, we integrate the model into hospital systems where it can assist with tasks like\n",
    "    flagging abnormal test results. This is done carefully with proper staff training and monitoring\n",
    "    protocols.\n",
    "\n",
    "7. **Monitoring**\n",
    "\n",
    "    After launch, we continuously track the model's performance in real-world use. Just like medical\n",
    "    guidelines evolve, we update the models as we get new data or discover ways to improve them.\n",
    "\n",
    "This ongoing cycle helps create AI tools that truly support clinical work while maintaining safety\n",
    "and reliability. Your expertise remains essential for interpreting results and making final\n",
    "decisions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024d295",
   "metadata": {},
   "source": [
    "## Part II: Let's build your first medical AI model!\n",
    "\n",
    "In this workshop, we will use a real-world medical dataset from the\n",
    "[WiDS Datathon 2020](https://www.kaggle.com/competitions/widsdatathon2020/data), which contains\n",
    "anonymized patient records from intensive care units (ICUs) around the world. The dataset includes a\n",
    "wide range of clinical features such as demographics, vital signs, laboratory results, and\n",
    "comorbidities collected during the first 24 hours of a patient's ICU stay.\n",
    "\n",
    "While the original competition focused on predicting in-hospital mortality (`hospital_death`), our\n",
    "goal will be to develop a model that predicts whether a patient has cirrhosis, using the `cirrhosis`\n",
    "column as our target variable. This shift allows us to explore the challenges and considerations\n",
    "involved in building AI models for different clinical outcomes, while practicing essential steps in\n",
    "the machine learning workflow.\n",
    "\n",
    "Let's first load the data and visualize it to understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4adb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set_theme(style=\"white\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c33f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/training_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b451fe",
   "metadata": {},
   "source": [
    "Plot below shows the distribution of each demographic traits including age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.histplot(data=df, x=\"age\", ax=axes[0])\n",
    "sns.histplot(data=df, x=\"gender\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd3568",
   "metadata": {},
   "source": [
    "This dataset also contains the prevalence of 6 datasets: leukemia, hepatic failure,\n",
    "immunosuppression, lymphoma, cirrhosis, and aids. Let's take a quick look on how each disease\n",
    "prevalence distributes across gender and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db710c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASES = [\"leukemia\", \"hepatic_failure\", \"immunosuppression\", \"lymphoma\", \"cirrhosis\", \"aids\"]\n",
    "long_df = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"patient_id\", \"gender\", \"ethnicity\"],\n",
    "    value_vars=DISEASES,\n",
    "    value_name=\"presence\",\n",
    "    var_name=\"disease\",\n",
    ")\n",
    "\n",
    "sns.catplot(\n",
    "    data=long_df[long_df[\"presence\"] == 1],\n",
    "    x=\"disease\",\n",
    "    col=\"gender\",\n",
    "    hue=\"disease\",\n",
    "    kind=\"count\",\n",
    "    aspect=2,\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2851bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=long_df[long_df[\"presence\"] == 1],\n",
    "    x=\"disease\",\n",
    "    col=\"ethnicity\",\n",
    "    col_wrap=3,\n",
    "    hue=\"disease\",\n",
    "    kind=\"count\",\n",
    "    legend=False,\n",
    "    aspect=1.5,\n",
    ")\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis=\"x\", rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b05c44",
   "metadata": {},
   "source": [
    "**üîç Findings**\n",
    "\n",
    "- **Mean age is 62**, left skewed. Younger people is underrepresented.\n",
    "- **Similar number of male and female**\n",
    "    - **Men are likely to have disease**.\n",
    "    - The difference is significant in cirrhosis, hepatic failure, aids, and leukemia. An educated\n",
    "      could be that **cirrhosis because men drink more**, **aids because gays are categorized as men**.\n",
    "- **77% of patients are white**.\n",
    "    - Caucasian vs Native American shows significant difference.\n",
    "    - Caucasian vs African American shows notable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a90f47",
   "metadata": {},
   "source": [
    "Now let's practice what we have discussed. From the list below, choose **two** or **three** problems\n",
    "that you are familiar with then proceed.\n",
    "\n",
    "Given a problem and a goal, which types of patient data should we collect? And how would it help\n",
    "constructing an accurate model? What are the other use cases in ICU care or medical practice that we\n",
    "can apply this solution to? Do they have the same format of data? Can we apply the same data\n",
    "cleaning method? If you cannot think of any, what about applying the same modeling technique to the\n",
    "following problems?\n",
    "\n",
    "1. Estimating ST-elevation from ECG signal\n",
    "2. Detecting lung cancer from CXR images\n",
    "3. Adjusting insulin dose from CGM data\n",
    "4. Sepsis prediction in the ICU\n",
    "5. Early warning system (EWS) for deterioration\n",
    "6. Data extraction from clinician notes for flowsheets\n",
    "7. Bed management\n",
    "\n",
    "Discuss your thoughts with your group!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a313770",
   "metadata": {},
   "source": [
    "## Part III: Monitoring your AI model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9cd32",
   "metadata": {},
   "source": [
    "TODO: Define the metrics and evaluate the model produce in the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253594a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Based on the problems you selected earlier, hat should be the evaluation metrics for those problems?\n",
    "\n",
    "1. Sepsis prediction in the ICU\n",
    "2. Early warning system (EWS)\n",
    "3. Data extraction from clinician notes for flowsheets\n",
    "4. Bed management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93e99f",
   "metadata": {},
   "source": [
    "TODO: Reveal the data bias problem with handpicked evaluation (choose specific groups and compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480459fd",
   "metadata": {},
   "source": [
    "What did we do wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a86920",
   "metadata": {},
   "source": [
    "## Part IV: Removing the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370de861",
   "metadata": {},
   "source": [
    "TODO: Reconstruct the model by removing the bias in the features\n",
    "\n",
    "TODO: Explain that there are other ways to remove the bias, e.g. through penalization,\n",
    "sampling techniques, special loss functions, diverse data retrieval, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43540b",
   "metadata": {},
   "source": [
    "At the end of this material, let's take a step further and discuss with the team of this issue.\n",
    "\n",
    "- Can you think of any example that bias would help training a more accurate model? And why would\n",
    "  the bias help?\n",
    "- Stick to that example. How do you know it is a fair bias? Or alternatively, how do you know if it\n",
    "  is unfair?\n",
    "- How can we prevent bias into machine learning lifecycle?\n",
    "- How do we know if ChatGPT is safe from bias? What questions should we ask in order to know the\n",
    "  answer?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-icu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
